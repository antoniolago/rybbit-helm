name: Test Helm Chart

on:
  pull_request:
    branches: [main, master]
  repository_dispatch:
    types: [rybbit-release]
  workflow_dispatch:
    inputs:
      rybbit_version:
        description: 'Rybbit version to test (e.g., v1.0.0 or latest)'
        required: false
        default: 'latest'

env:
  KIND_CLUSTER_NAME: rybbit-ci-test
  NAMESPACE: rybbit
  RELEASE_NAME: rybbit

jobs:
  lint:
    name: Lint Helm Chart
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Helm
        uses: azure/setup-helm@v4
        with:
          version: v3.14.0

      - name: Add Helm repositories
        run: |
          helm repo add cnpg https://cloudnative-pg.github.io/charts
          helm repo add altinity https://helm.altinity.com/
          helm repo update

      - name: Run Helm lint
        run: helm lint .

      - name: Run chart-testing lint
        uses: helm/chart-testing-action@v2
        with:
          version: v3.10.0
          config: .github/ct-config.yaml

      - name: Lint chart
        run: ct lint --config .github/ct-config.yaml --all

  template:
    name: Template Validation
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Helm
        uses: azure/setup-helm@v4
        with:
          version: v3.14.0

      - name: Update dependencies
        run: helm dependency update

      - name: Template chart
        run: helm template test-release . --namespace test --debug

      - name: Template with custom values
        run: |
          helm template test-release . \
            --namespace test \
            --set backend.replicaCount=2 \
            --set client.replicaCount=2 \
            --set postgresql.cluster.instances=3 \
            --debug

  integration-test:
    name: Integration Test (KinD)
    runs-on: ubuntu-latest
    needs: [lint, template]
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Helm
        uses: azure/setup-helm@v4
        with:
          version: v3.14.0

      - name: Create KinD cluster
        uses: helm/kind-action@v1
        with:
          cluster_name: ${{ env.KIND_CLUSTER_NAME }}
          config: .github/kind-config.yaml

      - name: Install CloudNativePG Operator
        run: |
          helm repo add cnpg https://cloudnative-pg.github.io/charts
          helm repo update
          helm install cnpg cnpg/cloudnative-pg \
            --namespace cnpg-system \
            --create-namespace \
            --wait \
            --timeout 300s

      - name: Update Helm dependencies
        run: helm dependency update

      - name: Install Rybbit chart
        run: |
          IMAGE_TAG="${{ github.event.inputs.rybbit_version || github.event.client_payload.version || 'latest' }}"
          
          helm upgrade --install ${{ env.RELEASE_NAME }} . \
            --namespace ${{ env.NAMESPACE }} \
            --create-namespace \
            --set backend.image.tag="${IMAGE_TAG}" \
            --set client.image.tag="${IMAGE_TAG}" \
            --set postgresql.cluster.instances=1 \
            --set clickhouse.clickhouse.replicasCount=1 \
            --set clickhouse.keeper.replicaCount=1 \
            --set backend.replicaCount=1 \
            --set client.replicaCount=1 \
            --set global.podDisruptionBudget.enabled=false \
            --wait \
            --timeout 600s

      - name: Wait for pods
        run: |
          echo "Waiting for all pods to be ready..."
          kubectl wait --for=condition=ready pod \
            -l app.kubernetes.io/instance=${{ env.RELEASE_NAME }} \
            -n ${{ env.NAMESPACE }} \
            --timeout=300s || true
          
          kubectl get pods -n ${{ env.NAMESPACE }}

      - name: Check deployments
        run: |
          kubectl get deployments -n ${{ env.NAMESPACE }}
          
          BACKEND_READY=$(kubectl get deployment ${{ env.RELEASE_NAME }}-backend \
            -n ${{ env.NAMESPACE }} \
            -o jsonpath='{.status.readyReplicas}' 2>/dev/null || echo "0")
          
          CLIENT_READY=$(kubectl get deployment ${{ env.RELEASE_NAME }}-client \
            -n ${{ env.NAMESPACE }} \
            -o jsonpath='{.status.readyReplicas}' 2>/dev/null || echo "0")
          
          echo "Backend ready replicas: $BACKEND_READY"
          echo "Client ready replicas: $CLIENT_READY"

      - name: Verify backend is fully operational
        run: |
          echo "=== Verifying backend logs for 'Server listening' ==="
          BACKEND_POD=$(kubectl get pods -n ${{ env.NAMESPACE }} \
            -l app.kubernetes.io/component=backend \
            -o jsonpath='{.items[0].metadata.name}')
          
          echo "Checking logs for backend pod: $BACKEND_POD"
          
          # Wait up to 60 seconds for the server to be listening
          for i in {1..12}; do
            if kubectl logs -n ${{ env.NAMESPACE }} $BACKEND_POD -c backend 2>/dev/null | grep -q "Server listening"; then
              echo "✓ Backend is fully operational - 'Server listening' found in logs"
              kubectl logs -n ${{ env.NAMESPACE }} $BACKEND_POD -c backend --tail=20
              exit 0
            fi
            echo "Attempt $i/12: Waiting for backend to start listening..."
            sleep 5
          done
          
          echo "ERROR: Backend did not show 'Server listening' in logs within 60 seconds"
          echo "=== Full backend logs ==="
          kubectl logs -n ${{ env.NAMESPACE }} $BACKEND_POD -c backend || true
          exit 1

      - name: Show pod logs on failure
        if: failure()
        run: |
          echo "=== Backend logs ==="
          kubectl logs -n ${{ env.NAMESPACE }} -l app.kubernetes.io/component=backend --tail=100 || true
          
          echo "=== Client logs ==="
          kubectl logs -n ${{ env.NAMESPACE }} -l app.kubernetes.io/component=client --tail=100 || true
          
          echo "=== Pod descriptions ==="
          kubectl describe pods -n ${{ env.NAMESPACE }}

      - name: Cleanup
        if: always()
        run: |
          echo "=== Cleaning up ==="
          
          # Manually delete ClickHouse resources that might hang helm uninstall
          echo "Deleting ClickHouseInstallation objects..."
          kubectl delete clickhouseinstallation --all --all-namespaces --ignore-not-found=true --force --grace-period=0 || true
          kubectl delete clickhousekeeperinstallation --all --all-namespaces --ignore-not-found=true --force --grace-period=0 || true
          
          # Delete the helm release
          helm uninstall ${{ env.RELEASE_NAME }} -n ${{ env.NAMESPACE }} || true
          
          # Delete namespace with force to avoid hanging
          kubectl delete namespace ${{ env.NAMESPACE }} --ignore-not-found --force --grace-period=0 || true
          echo "✓ Cleanup completed"
